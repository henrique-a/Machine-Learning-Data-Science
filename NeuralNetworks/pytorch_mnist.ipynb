{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([5, 6, 6, 6, 4, 4, 8, 7, 4, 0])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(data[0][0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # fully connected layer\n",
    "        self.fc1 = nn.Linear(784, 64) # 784 = 28 x 28 (image size)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10) # 10 classes (0 to 9)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n",
      "torch.Size([784])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand((28,28))\n",
    "print(X.shape)\n",
    "X = X.view(28*28)\n",
    "print(X.shape)\n",
    "X = X.view(-1,28*28)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2477, -2.3045, -2.2410, -2.2303, -2.2908, -2.3340, -2.2700, -2.3366,\n",
       "         -2.4210, -2.3667]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0062, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0075, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0117, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset: # data is a batch of features and labels\n",
    "        X, y = data\n",
    "        net.zero_grad() # Sets gradients of all model parameters to zero\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        loss = F.nll_loss(output, y) # Negative log likelihood loss\n",
    "        loss.backward() # Backpropagate\n",
    "        optimizer.step() # Adjust the weights\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.973\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad(): # Disabling gradient calculation\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[0].view(-1, 28*28))[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
