{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single layer perceptron\n",
    "class SLP(object):    \n",
    "    def __init__(self, n_weights = 3, rate=1):\n",
    "        \n",
    "        # Neural network variables\n",
    "        self.n_weights = n_weights # number of weights\n",
    "        self.rate = rate # learning rate \n",
    "        \n",
    "        # Set initial random weights for the network\n",
    "        W = np.array([random.uniform(-1,1) for _ in range(self.n_weights)])\n",
    "        #W = np.zeros(self.n_weights)\n",
    "        W = np.insert(W, 0, 1, axis=0) # inserting bias\n",
    "        self.W = W.reshape((-1,1))  \n",
    "                \n",
    "    \n",
    "    # Activation function\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    # Activation function derivative\n",
    "    def d_sigmoid(self, x): # derivate of sigmoid\n",
    "        return self.sigmoid(x)*(1 - self.sigmoid(x))\n",
    "    \n",
    "    def V(self, X):\n",
    "        return np.diag(self.d_sigmoid(X @ self.W).flatten())\n",
    "    \n",
    "    def H(self, X):\n",
    "        #print(f'V: {self.V(X)}')\n",
    "        return X.T @ self.V(X) @ X\n",
    "\n",
    "    \n",
    "    # Binary Cross-Entropy loss function\n",
    "    def loss(self, Z, Y):\n",
    "        return np.asscalar((-1/len(Y)) * ( Y.T @ np.log(Z + (1.e-10)) + (1 - Y).T @ np.log(1 - Z + (1.e-10)) )) \n",
    "\n",
    "    # Gradient of loss function\n",
    "    def gradient_loss(self, Z, Y):\n",
    "        dL = Y.T @ (1/Z) + (1 - Y).T @ (1/(Z - 1))\n",
    "        return np.asscalar((-1/len(Y)) * dL)\n",
    "    \n",
    "    # Foward step\n",
    "    def forward(self, X):\n",
    "        V =  X @ self.W\n",
    "        \n",
    "        Z = self.sigmoid(V)\n",
    "        \n",
    "        return V,Z\n",
    "    \n",
    "    # Train neural network\n",
    "    def train(self, X, Y):\n",
    "        k = 0\n",
    "        print(\"Epoch {}:\".format(k))\n",
    "        V, Z = self.forward(X)\n",
    "        print(\"loss: {}\".format(self.loss(Z,Y)))\n",
    "        print(\"Predict: {}\".format(self.predict(X,Y)))\n",
    "        loss = np.inf        \n",
    "        # Perform a gradient descent algorithm\n",
    "        while abs(loss) > 0.001 and k < 1000:\n",
    "            k = k + 1\n",
    "            #W_new = self.W - self.rate * self.gradient_loss(Z, Y) * X.T @ self.d_sigmoid(V)\n",
    "            W_new = self.W + self.rate * np.linalg.pinv(self.H(X)) @ X.T @ (Y - Z)\n",
    "\n",
    "            self.W = W_new \n",
    "\n",
    "            print(\"Epoch {}:\".format(k))\n",
    "\n",
    "            V, Z = self.forward(X)\n",
    "            loss = self.loss(Z,Y)\n",
    "            print(f\"loss: {loss}\")\n",
    "            print(f\"Predict: {self.predict(X,Y)}\")\n",
    "    \n",
    "    # Predict class of a sample\n",
    "    def predict(self, X, Y):\n",
    "        Z = self.forward(X)[1].flatten().round()\n",
    "        errors = 0\n",
    "        for i,pred in enumerate(Z):\n",
    "            if pred != Y[i]:\n",
    "                errors += 1\n",
    "\n",
    "        acc = 1 - (errors / len(Y))\n",
    "        return acc\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = SLP(n_weights=30, rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 31)\n",
      "Epoch 0:\n",
      "loss: 1.0601398867401493\n",
      "Predict: 0.609841827768014\n",
      "Epoch 1:\n",
      "loss: 0.6927003366598253\n",
      "Predict: 0.6625659050966608\n",
      "Epoch 2:\n",
      "loss: 0.5723690819039344\n",
      "Predict: 0.7047451669595782\n",
      "Epoch 3:\n",
      "loss: 0.49601690772108864\n",
      "Predict: 0.7504393673110721\n",
      "Epoch 4:\n",
      "loss: 0.4403922537001333\n",
      "Predict: 0.7943760984182777\n",
      "Epoch 5:\n",
      "loss: 0.3967429138664678\n",
      "Predict: 0.8312829525483304\n",
      "Epoch 6:\n",
      "loss: 0.36089524766444114\n",
      "Predict: 0.8576449912126538\n",
      "Epoch 7:\n",
      "loss: 0.33055935984616647\n",
      "Predict: 0.875219683655536\n",
      "Epoch 8:\n",
      "loss: 0.3043499525903436\n",
      "Predict: 0.8945518453427065\n",
      "Epoch 9:\n",
      "loss: 0.28136591319288956\n",
      "Predict: 0.9103690685413005\n",
      "Epoch 10:\n",
      "loss: 0.26098673898605196\n",
      "Predict: 0.9209138840070299\n",
      "Epoch 11:\n",
      "loss: 0.24276488717050504\n",
      "Predict: 0.9244288224956063\n",
      "Epoch 12:\n",
      "loss: 0.2263649614128756\n",
      "Predict: 0.9332161687170475\n",
      "Epoch 13:\n",
      "loss: 0.2115275339268214\n",
      "Predict: 0.9384885764499121\n",
      "Epoch 14:\n",
      "loss: 0.19804667696255374\n",
      "Predict: 0.9420035149384886\n",
      "Epoch 15:\n",
      "loss: 0.18575546063499118\n",
      "Predict: 0.9490333919156415\n",
      "Epoch 16:\n",
      "loss: 0.17451624209887676\n",
      "Predict: 0.9578207381370826\n",
      "Epoch 17:\n",
      "loss: 0.16421392399666335\n",
      "Predict: 0.9595782073813708\n",
      "Epoch 18:\n",
      "loss: 0.15475110798091823\n",
      "Predict: 0.9613356766256591\n",
      "Epoch 19:\n",
      "loss: 0.1460444971870247\n",
      "Predict: 0.9613356766256591\n",
      "Epoch 20:\n",
      "loss: 0.1380221524217525\n",
      "Predict: 0.9630931458699473\n",
      "Epoch 21:\n",
      "loss: 0.1306213562034184\n",
      "Predict: 0.9666080843585237\n",
      "Epoch 22:\n",
      "loss: 0.12378692843662352\n",
      "Predict: 0.9718804920913884\n",
      "Epoch 23:\n",
      "loss: 0.11746989081132476\n",
      "Predict: 0.9718804920913884\n",
      "Epoch 24:\n",
      "loss: 0.11162640681116917\n",
      "Predict: 0.9736379613356766\n",
      "Epoch 25:\n",
      "loss: 0.10621693742411459\n",
      "Predict: 0.9736379613356766\n",
      "Epoch 26:\n",
      "loss: 0.10120555409495052\n",
      "Predict: 0.9736379613356766\n",
      "Epoch 27:\n",
      "loss: 0.09655934670864376\n",
      "Predict: 0.9753954305799648\n",
      "Epoch 28:\n",
      "loss: 0.09224786539218968\n",
      "Predict: 0.9771528998242531\n",
      "Epoch 29:\n",
      "loss: 0.08824254886378723\n",
      "Predict: 0.9771528998242531\n",
      "Epoch 30:\n",
      "loss: 0.08451611623314295\n",
      "Predict: 0.9771528998242531\n",
      "Epoch 31:\n",
      "loss: 0.08104192460039047\n",
      "Predict: 0.9771528998242531\n",
      "Epoch 32:\n",
      "loss: 0.07779333722935253\n",
      "Predict: 0.9771528998242531\n",
      "Epoch 33:\n",
      "loss: 0.07474328479638971\n",
      "Predict: 0.9789103690685413\n",
      "Epoch 34:\n",
      "loss: 0.07186455878229572\n",
      "Predict: 0.9789103690685413\n",
      "Epoch 35:\n",
      "loss: 0.06913181497553415\n",
      "Predict: 0.9789103690685413\n",
      "Epoch 36:\n",
      "loss: 0.0665255464713938\n",
      "Predict: 0.9789103690685413\n",
      "Epoch 37:\n",
      "loss: 0.0640351054693994\n",
      "Predict: 0.9824253075571178\n",
      "Epoch 38:\n",
      "loss: 0.061656913588724216\n",
      "Predict: 0.9876977152899824\n",
      "Epoch 39:\n",
      "loss: 0.05938992828654709\n",
      "Predict: 0.9876977152899824\n",
      "Epoch 40:\n",
      "loss: 0.05723288638673471\n",
      "Predict: 0.9876977152899824\n",
      "Epoch 41:\n",
      "loss: 0.05518371102453146\n",
      "Predict: 0.9876977152899824\n",
      "Epoch 42:\n",
      "loss: 0.053239638968484146\n",
      "Predict: 0.9876977152899824\n",
      "Epoch 43:\n",
      "loss: 0.05139740672911074\n",
      "Predict: 0.9876977152899824\n",
      "Epoch 44:\n",
      "loss: 0.04965342454810262\n",
      "Predict: 0.9876977152899824\n",
      "Epoch 45:\n",
      "loss: 0.04800394963071173\n",
      "Predict: 0.9876977152899824\n",
      "Epoch 46:\n",
      "loss: 0.04644523227111878\n",
      "Predict: 0.9876977152899824\n",
      "Epoch 47:\n",
      "loss: 0.044973602916101\n",
      "Predict: 0.9876977152899824\n",
      "Epoch 48:\n",
      "loss: 0.043585489229470614\n",
      "Predict: 0.9876977152899824\n",
      "Epoch 49:\n",
      "loss: 0.04227737522534296\n",
      "Predict: 0.9876977152899824\n",
      "Epoch 50:\n",
      "loss: 0.041045728862853584\n",
      "Predict: 0.9876977152899824\n",
      "Epoch 51:\n",
      "loss: 0.039886927643534645\n",
      "Predict: 0.9894551845342706\n",
      "Epoch 52:\n",
      "loss: 0.038797205136860496\n",
      "Predict: 0.9894551845342706\n",
      "Epoch 53:\n",
      "loss: 0.037772629554747715\n",
      "Predict: 0.9894551845342706\n",
      "Epoch 54:\n",
      "loss: 0.036809114329042894\n",
      "Predict: 0.9894551845342706\n",
      "Epoch 55:\n",
      "loss: 0.035902454231612056\n",
      "Predict: 0.9912126537785588\n",
      "Epoch 56:\n",
      "loss: 0.03504837962664834\n",
      "Predict: 0.9912126537785588\n",
      "Epoch 57:\n",
      "loss: 0.03424262369010534\n",
      "Predict: 0.9912126537785588\n",
      "Epoch 58:\n",
      "loss: 0.03348099922607051\n",
      "Predict: 0.9912126537785588\n",
      "Epoch 59:\n",
      "loss: 0.03275947972521949\n",
      "Predict: 0.9912126537785588\n",
      "Epoch 60:\n",
      "loss: 0.032074271977182905\n",
      "Predict: 0.9912126537785588\n",
      "Epoch 61:\n",
      "loss: 0.0314218562642982\n",
      "Predict: 0.9912126537785588\n",
      "Epoch 62:\n",
      "loss: 0.03079895979068332\n",
      "Predict: 0.9929701230228472\n",
      "Epoch 63:\n",
      "loss: 0.030202427269254224\n",
      "Predict: 0.9947275922671354\n",
      "Epoch 64:\n",
      "loss: 0.02962897177919171\n",
      "Predict: 0.9947275922671354\n",
      "Epoch 65:\n",
      "loss: 0.029074859501283933\n",
      "Predict: 0.9964850615114236\n",
      "Epoch 66:\n",
      "loss: 0.028535762134480183\n",
      "Predict: 0.9964850615114236\n",
      "Epoch 67:\n",
      "loss: 0.02800720538007388\n",
      "Predict: 0.9964850615114236\n",
      "Epoch 68:\n",
      "loss: 0.02748548522581835\n",
      "Predict: 0.9964850615114236\n",
      "Epoch 69:\n",
      "loss: 0.02696752877347043\n",
      "Predict: 0.9964850615114236\n",
      "Epoch 70:\n",
      "loss: 0.026449346234550378\n",
      "Predict: 0.9964850615114236\n",
      "Epoch 71:\n",
      "loss: 0.025925294929204482\n",
      "Predict: 0.9964850615114236\n",
      "Epoch 72:\n",
      "loss: 0.02538888937935431\n",
      "Predict: 0.9964850615114236\n",
      "Epoch 73:\n",
      "loss: 0.024833998921214507\n",
      "Predict: 0.9964850615114236\n",
      "Epoch 74:\n",
      "loss: 0.02425608321683774\n",
      "Predict: 0.9964850615114236\n",
      "Epoch 75:\n",
      "loss: 0.023653472845517866\n",
      "Predict: 0.9964850615114236\n",
      "Epoch 76:\n",
      "loss: 0.023027254707042897\n",
      "Predict: 0.9947275922671354\n",
      "Epoch 77:\n",
      "loss: 0.022380053963490933\n",
      "Predict: 0.9947275922671354\n",
      "Epoch 78:\n",
      "loss: 0.021716523531123202\n",
      "Predict: 0.9947275922671354\n",
      "Epoch 79:\n",
      "loss: 0.021045597255569287\n",
      "Predict: 0.9947275922671354\n",
      "Epoch 80:\n",
      "loss: 0.020380919959186807\n",
      "Predict: 0.9929701230228472\n",
      "Epoch 81:\n",
      "loss: 0.019736946914680368\n",
      "Predict: 0.9929701230228472\n",
      "Epoch 82:\n",
      "loss: 0.019123429625694154\n",
      "Predict: 0.9929701230228472\n",
      "Epoch 83:\n",
      "loss: 0.018542967294328496\n",
      "Predict: 0.9929701230228472\n",
      "Epoch 84:\n",
      "loss: 0.017992172430806065\n",
      "Predict: 0.9929701230228472\n",
      "Epoch 85:\n",
      "loss: 0.017463907458088835\n",
      "Predict: 0.9929701230228472\n",
      "Epoch 86:\n",
      "loss: 0.016948847665577402\n",
      "Predict: 0.9929701230228472\n",
      "Epoch 87:\n",
      "loss: 0.01643598396906944\n",
      "Predict: 0.9929701230228472\n",
      "Epoch 88:\n",
      "loss: 0.015911912697196995\n",
      "Predict: 0.9929701230228472\n",
      "Epoch 89:\n",
      "loss: 0.015358302188245663\n",
      "Predict: 0.9929701230228472\n",
      "Epoch 90:\n",
      "loss: 0.014746573642898355\n",
      "Predict: 0.9929701230228472\n",
      "Epoch 91:\n",
      "loss: 0.014030051714192823\n",
      "Predict: 0.9947275922671354\n",
      "Epoch 92:\n",
      "loss: 0.013143730924497872\n",
      "Predict: 0.9947275922671354\n",
      "Epoch 93:\n",
      "loss: 0.01205135529472275\n",
      "Predict: 0.9964850615114236\n",
      "Epoch 94:\n",
      "loss: 0.010841629466844992\n",
      "Predict: 0.9964850615114236\n",
      "Epoch 95:\n",
      "loss: 0.00967365701059746\n",
      "Predict: 0.9982425307557118\n",
      "Epoch 96:\n",
      "loss: 0.008617699021417126\n",
      "Predict: 0.9982425307557118\n",
      "Epoch 97:\n",
      "loss: 0.007677360682050209\n",
      "Predict: 1.0\n",
      "Epoch 98:\n",
      "loss: 0.006840413549395808\n",
      "Predict: 1.0\n",
      "Epoch 99:\n",
      "loss: 0.006099860168553058\n",
      "Predict: 1.0\n",
      "Epoch 100:\n",
      "loss: 0.005447143640179041\n",
      "Predict: 1.0\n",
      "Epoch 101:\n",
      "loss: 0.004871703145827036\n",
      "Predict: 1.0\n",
      "Epoch 102:\n",
      "loss: 0.0043630661413474135\n",
      "Predict: 1.0\n",
      "Epoch 103:\n",
      "loss: 0.003912152746625475\n",
      "Predict: 1.0\n",
      "Epoch 104:\n",
      "loss: 0.00351138057383293\n",
      "Predict: 1.0\n",
      "Epoch 105:\n",
      "loss: 0.0031544049176136465\n",
      "Predict: 1.0\n",
      "Epoch 106:\n",
      "loss: 0.002835866155516347\n",
      "Predict: 1.0\n",
      "Epoch 107:\n",
      "loss: 0.002551192916733092\n",
      "Predict: 1.0\n",
      "Epoch 108:\n",
      "loss: 0.00229645290716102\n",
      "Predict: 1.0\n",
      "Epoch 109:\n",
      "loss: 0.002068239594686702\n",
      "Predict: 1.0\n",
      "Epoch 110:\n",
      "loss: 0.0018635852542946184\n",
      "Predict: 1.0\n",
      "Epoch 111:\n",
      "loss: 0.001679893079916489\n",
      "Predict: 1.0\n",
      "Epoch 112:\n",
      "loss: 0.0015148829630468035\n",
      "Predict: 1.0\n",
      "Epoch 113:\n",
      "loss: 0.001366547180949009\n",
      "Predict: 1.0\n",
      "Epoch 114:\n",
      "loss: 0.001233113512606437\n",
      "Predict: 1.0\n",
      "Epoch 115:\n",
      "loss: 0.001113014154019276\n",
      "Predict: 1.0\n",
      "Epoch 116:\n",
      "loss: 0.0010048593179983868\n",
      "Predict: 1.0\n",
      "Epoch 117:\n",
      "loss: 0.0009074147011725506\n",
      "Predict: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:18: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "Y = data.target.reshape(-1,1)\n",
    "\n",
    "X = data.data\n",
    "\n",
    "\n",
    "X = preprocessing.scale(X)\n",
    "\n",
    "X = np.insert(X,0,1,axis=1) # inserting bias\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "nn.train(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 2, 0],\n",
       "       [0, 0, 3]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3]])\n",
    "a = a.flatten()\n",
    "np.diag(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
